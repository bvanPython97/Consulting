message(sprintf("%s YOU LOSE!", value))
}
else {
total <- 0
while (total != value & total != 7){
print("AGAIN!")
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
total <- dice1 + dice2
}
if (total == value){
message(sprintf("%s YOU WIN!", total))
}
else message(sprintf("%s YOU LOSE!", total))
}
}
craps()
craps <- function(){
dicelist <- c(1,2,3,4,5,6)
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
value <- dice1 + dice2
if (value == 7 | value == 11){
message(sprintf("%s YOU WIN!", value))
}
else if (value == 2 | value == 3 | value == 12) {
message(sprintf("%s YOU LOSE!", value))
}
else {
total <- 0
while (total != value & total != 7){
print("AGAIN!")
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
total <- dice1 + dice2
}
if (total == value){
message(sprintf("%s YOU WIN!", total))
}
else message(sprintf("%s YOU LOSE!", total))
}
}
craps()
craps <- function(){
dicelist <- c(1,2,3,4,5,6)
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
value <- dice1 + dice2
if (value == 7 | value == 11){
message(sprintf("%s YOU WIN!", value))
}
else if (value == 2 | value == 3 | value == 12) {
message(sprintf("%s YOU LOSE!", value))
}
else {
total <- 0
while (total != value & total != 7){
print("AGAIN!")
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
total <- dice1 + dice2
}
if (total == value){
message(sprintf("%s YOU WIN!", total))
}
else message(sprintf("%s YOU LOSE!", total))
}
}
craps()
craps <- function(){
dicelist <- c(1,2,3,4,5,6)
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
value <- dice1 + dice2
if (value == 7 | value == 11){
message(sprintf("%s YOU WIN!", value))
}
else if (value == 2 | value == 3 | value == 12) {
message(sprintf("%s YOU LOSE!", value))
}
else {
total <- 0
while (total != value & total != 7){
print("AGAIN!")
dice1 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("1st dice %s",dice1))
dice2 <- sample(dicelist, 1, replace = TRUE)
message(sprintf("2nd dice %s",dice2))
total <- dice1 + dice2
}
if (total == value){
message(sprintf("%s YOU WIN!", total))
}
else message(sprintf("%s YOU LOSE!", total))
}
}
craps()
t <- seq(0,10, by = 0.00001)
x <- sqrt(t)*cos(2*pi*t)
y <- sqrt(t)*sin(2*pi*t)
plot(x,y,cex = 0.01)
t <- seq(0,10, by = 0.00001)
x <- sqrt(t)*cos(2*pi*t)
y <- sqrt(t)*sin(2*pi*t)
plot(x,y,cex = 0.1)
knitr::opts_chunk$set(echo = TRUE)
library(class)
train_df <- read.csv("PA_HW1_train.csv")
train_df_pred <- knn(train = train_df[c(1,2)], test = train_df[c(1,2)], cl = train_df$col, k = 1)
tb <- table(train_df_pred, train_df$col)
tb
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tb)
test_df <- read.csv("PA_HW1_test.csv")
pred <- knn(train = train_df[c(1,2)], test = test_df[c(1,2)], cl = train_df$col, k = 1)
tb <- table(pred, test_df$col)
tb
accuracy(tb)
library(tidyverse)
library(ggplot2)
k_list <- c(1:100)
set.seed(1)
train_100 <- sapply(k_list, function(x){
train_pred <- knn(train_df[c(1,2)], train_df[c(1,2)], cl=train_df$col, k = x, prob = T)
tb <- table(train_pred, train_df$col)
error <- (tb[2]+tb[3])/175
return(error)
}
)
test_100 <- sapply(k_list, function(x){
test_pred <- knn(train_df[c(1,2)], test = test_df[c(1,2)], cl = train_df$col, k = x, prob = T)
tb <- table(test_pred, test_df$col)
error <- (tb[2]+tb[3])/1750
return(error)
}
)
ggplot() +
geom_line(aes(x = k_list, y = train_100, color = 'Train')) +
geom_line(aes(x = k_list, y = test_100, color = 'Test')) +
xlab('k') +
ylab("Error")
plt <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
geom_point()
plt
library(MASS)
fit <- lda(Species ~ Sepal.Length + Sepal.Width, data = iris)
prd <- predict(fit)
table(iris$Species, prd$class)
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha = 0.01)
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha = 0.05)
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha = 0.005)
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha = 0.01)
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha = 0.01) +
title("Sepal Width vs Sepal Length For 3 Species")
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha =0.01,
title("Sepal Width vs Sepal Length For 3 Species"))
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha =0.01) +
ggtitle("Sepal Length and Sepal Width of Iris Species ")
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha =0.01) +
print(ggtitle("Sepal Length and Sepal Width of Iris Species "))
grid <- expand.grid(seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = 0.01), seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = 0.01))
names(grid) <- c("Sepal.Length", "Sepal.Width")
pred <- predict(fit, grid)
bounds <- data.frame(pred$class, grid)
plt + geom_point(data = bounds, aes(x = Sepal.Length, y = Sepal.Width, color = pred.class), alpha =0.01) +
ggtitle("Sepal Length and Sepal Width of Iris Species ")
setwd("~/")
round1 <- read.csv("round1_updated.csv",header = 1)
setwd("~/")
round1 <- read.csv("round1_updated.csv",header = 1)
round1 <- read.csv("round1_updated",header = 1)
setwd("~/")
round1 <- read.csv("round1_updated",header = 1)
round1 <- read.csv("round1_updated.csv",header = 1)
round1 <- read.csv("round1_updated.csv")
setwd("C:/Users/baova/OneDrive/Desktop/Loyola Assignments/Consulting")
round1 <- read.csv("round1_updated.csv")
View(round1)
library(dplyr)
df <- round1 %>% filter(event_type != "scorecard")
df <- df %>% filter(game_name != "playlist")
View(df)
df <- subset(df, select = -sessionid)
View(df)
df <- subset(df, select = -c(trai_timestamp, response_timestamp))
df <- subset(df, select = -c(trail_timestamp, response_timestamp))
View(df)
df <- subset(df, select = -c(trial_timestamp, response_timestamp))
source("~/OneDrive - Loyola University Chicago/Fifth Year/Fall Classes/STAT 488/Silton Project/Rounds 1 - 6 Data Files (updated July 2021, USE THIS!)/File Merge 100421.R", echo=TRUE)
library(gitcreds)
gitcreds_set()
library(gitcreds)
gitcreds_set()
getwd()
#Setting working directory to a spot on my OneDrive [CHANGE THIS]
setwd("https://github.com/bvanPython97/Consulting.git")
#Setting working directory to a spot on my OneDrive [CHANGE THIS]
setwd(https://github.com/bvanPython97/Consulting.git)
#Setting working directory to a spot on my OneDrive [CHANGE THIS]
setwd("https://github.com/bvanPython97/Consulting.git")
#Reading timepoints 1-6
R1<-read.csv("round1_updated.csv")
R1
R4<-read.csv("round4_updated.csv")
R5<-read.csv("round5_updated.csv")
R2<-read.csv("round2_updated.csv")
#Reading timepoints 1-6
R1<-read.csv("round1_updated.csv")
R2<-read.csv("round2_updated.csv")
R3<-read.csv("round3_updated.csv")
R4<-read.csv("round4_updated.csv")
R5<-read.csv("round5_updated.csv")
R6<-read.csv("round6_updated.csv")
n(R5)
str(R5)
R5<- R5%>%
filter(level_start_timestamp != "2021-03-25T18:55:58.767Z")
library(tidyverse)
R5<- R5%>%
filter(level_start_timestamp != "2021-03-25T18:55:58.767Z")
str(R5)
getwd()
library(tidyverse)
#Reading timepoints 1-6
R1<-read.csv("round1_updated.csv")
R2<-read.csv("round2_updated.csv")
R3<-read.csv("round3_updated.csv")
R4<-read.csv("round4_updated.csv")
R5<-read.csv("round5_updated.csv")
R6<-read.csv("round6_updated.csv")
#Was at 1049 (16 duplicates)
str(R5)
#Can filter out using unique timestamp from csv file
R5<- R5%>%
filter(level_start_timestamp != "2021-03-25T18:55:58.767Z")
#Now at 1033
str(R5)
#Was at 1049 (16 duplicates)
nrow(R5)
#Now at 1033
nrow(R5)
#This next step has multiple purposes. First, we are adding "semester" and "timepoint"
#variables to the dataset. Since "user1", "user2"... "usern" was used for both
#semesters, despite these representing different people, I created a new ID variable.
#For semester 1, it is the old ID +100; for semester 2, it is +200.
R1<-mutate(R1, semester=1, timepoint=1, ID = as.factor(as.numeric(gsub("user", "", userid))+100))
R2<-mutate(R2, semester=1, timepoint=2, ID = as.factor(as.numeric(gsub("user", "", userid))+100))
R3<-mutate(R3, semester=1, timepoint=3, ID = as.factor(as.numeric(gsub("user", "", userid))+100))
R4<-mutate(R4, semester=2, timepoint=1, ID = as.factor(as.numeric(gsub("user", "", userid))+200))
R5<-mutate(R5, semester=2, timepoint=2, ID = as.factor(as.numeric(gsub("user", "", userid))+200))
R6<-mutate(R6, semester=2, timepoint=3, ID = as.factor(as.numeric(gsub("user", "", userid))+200))
#Combining all six datasets
Full<-rbind(R1, R2, R3, R4, R5, R6)
#Ensuring the data looks correct and everything merged as expected
str(Full)
#The scorecard variable gives us information about each specific trial. I created
#a new dataset with only the scorecards for each user on each game
Scores<-filter(Full, event_type == "scorecard")
#We can get an idea of what is included (and what is not relevant) for this new dataset
summary(Scores)
str(Scores)
#I then mutated this to only retain variables we are interested in. The others were
#specific to individual items on each trial
Scores2<-select(Scores, c(ID, semester, timepoint,
game_name, correct_count, incorrect_count,
total_trials, fastest_reaction_time, median_reaction_time,
average_reaction_time, level_total_time
))
#We can view our new dataset to ensure it looks correct
str(Scores2)
view(Scores2)
#Create second correct_count variable
Scores2$correct_count2 = Scores2$total_trials-Scores2$incorrect_count
#Create "check" variable that is the difference between two counts
Scores2$countcheck = Scores2$correct_count - Scores2$correct_count2
#View summary by game type
Scores2%>%
group_by(game_name)%>%
summarize(min_corr = min(correct_count), min_corr2 = min(correct_count2),
max_corr = max(correct_count), max_corr2 = max(correct_count2),
min_check = min(countcheck), max_check = max(countcheck))
Scores2 <- Scores2%>%
mutate(correct_count2 = ifelse(game_name == "hand swype",
correct_count2 -1,
correct_count2))
#Create "check" variable that is the difference between two counts
Scores2$countcheck = Scores2$correct_count - Scores2$correct_count2
#View summary by game type
Scores2%>%
group_by(game_name)%>%
summarize(min_corr = min(correct_count), min_corr2 = min(correct_count2),
max_corr = max(correct_count), max_corr2 = max(correct_count2),
min_check = min(countcheck), max_check = max(countcheck))
#I then added a value for the proportion of correct responses, as a possible outcome
#for later
Scores2<-mutate(Scores2, prop_cor = (correct_count2/(correct_count2+incorrect_count)))
#Next, I want to summarize each timepoint for each individual.
#Ideally, we should have five values, one for each game, in each of these rows.
countScores<- Scores2%>%
group_by(ID, semester, timepoint)%>%
summarize(count = n())
countScores
#Unfortunately, we see that is not true
df<-data.frame(countScores)
df%>%
summarize(min=min(count), max=max(count))
#We see that ID 119 only has a single timepoint when we sort ascending
head(df[order(df$count),])
#We see that ID 206 has an extra timepoint when we sort descending. Returning to
#the original CSV for round5, we confirm that user6 (ID206) did quick tap level 2
#twice. We should likely remove one of these two trials.
head(df[order(-df$count),])
#Counting number of trials for each participant and each game
Scores2%>%
group_by(game_name)%>%
summarize(min_trials = min(total_trials),
max_trials = max(total_trials),
avg_trials = mean(total_trials))
#We can look at the number of trials for each participant using the code below
Scores2%>%
filter(game_name == "hand swype")%>%
ggplot(aes(x = timepoint, y = total_trials))+
geom_point()+
geom_line()+
geom_hline(yintercept = 34.3, color = "red", linetype = "dashed")+
facet_wrap(.~ID)
#See how correct_count is correlated with total trials
#Similarly, average reaction time is correlated with both
Scores2%>%
filter(game_name == "hand swype")%>%
ggplot(aes(y=total_trials, x = correct_count2))+
geom_point()
Scores2%>%
filter(game_name == "hand swype")%>%
ggplot(aes(y=total_trials, x = average_reaction_time))+
geom_point()+
geom_function(fun = function(x) 5/((x/5000)^1.5)+10)
Scores2%>%
filter(game_name == "hand swype")%>%
summarize(mean(average_reaction_time),
sd(average_reaction_time),
min(average_reaction_time),
min(total_trials))
Scores2%>%
filter(game_name == "hand swype")%>%
ggplot(aes(y=correct_count2, x = average_reaction_time))+
geom_point()
#Our next step is to create datasets for each of the game conditions. We first make
#a "long" version of the dataset with one row per timepoint
#This dataset will be necessary for analysis
ColorTrick1<-filter(Scores2, game_name == "color trick 1")
#Then we create a "wide" dataset with one row per participant
#This dataset will be helpful for descriptive statistics
CT1W<-pivot_wider(data = ColorTrick1,
names_from = timepoint,
values_from = c(correct_count2, incorrect_count,
total_trials,
fastest_reaction_time, median_reaction_time,
average_reaction_time, level_total_time))
#We can do the same for CT2
ColorTrick2<-filter(Scores2, game_name == "color trick 2")
CT2W<-pivot_wider(data = ColorTrick2,
names_from = timepoint,
values_from = c(correct_count2, incorrect_count,
total_trials,
fastest_reaction_time, median_reaction_time,
average_reaction_time, level_total_time))
#Next for CT3
ColorTrick3<-filter(Scores2, game_name == "color trick 3")
CT3W<-pivot_wider(data = ColorTrick3,
names_from = timepoint,
values_from = c(correct_count2, incorrect_count,
total_trials,
fastest_reaction_time, median_reaction_time,
average_reaction_time, level_total_time))
#Then for HS
HandSwipe<-filter(Scores2, game_name == "hand swype")
HSW<-pivot_wider(data = HandSwipe,
names_from = timepoint,
values_from = c(correct_count2, incorrect_count,
total_trials,
fastest_reaction_time, median_reaction_time,
average_reaction_time, level_total_time))
#Finally for QT2
QuickTap<-filter(Scores2, game_name == "quick tap level 2")
QT2<-pivot_wider(data = QuickTap,
names_from = timepoint,
values_from = c(correct_count2, incorrect_count,
total_trials,
fastest_reaction_time, median_reaction_time,
average_reaction_time, level_total_time))
#Next, we can start to visualize trajectories
#We first load the lattice package in R
library(lattice)
#We can make a "spaghetti" plot showing each trajectory across semesters using ggplot
#We first do this for the proportion correct
ColorTrick1%>%
ggplot(aes(x=timepoint, y=prop_cor, color=ID))+
geom_point()+
geom_line()+
facet_wrap(.~semester)+
ylab("Proportion Correct")
#We can also break the visualizations up into panels, one for each participant
xyplot(prop_cor ~ timepoint | ID, data = ColorTrick1, as.table = T,
xlab = "Timepoint", ylab = "Proportion Correct", grid = T, pch = 19,
type = c("p", "r"), col.line = "darkblue", lwd = 3, lty = 4 )
#We can create the same plots for average reaction time
ColorTrick1%>%
ggplot(aes(x=timepoint, y=average_reaction_time, color=ID))+
geom_point()+
geom_line()+
facet_wrap(.~semester)+
ylab("Reaction Time")
xyplot(average_reaction_time ~ timepoint | ID, data = ColorTrick1, as.table = T,
xlab = "Timepoint", ylab = "Reaction Time", grid = T, pch = 19,
type = c("p", "r"), col.line = "darkblue", lwd = 3, lty = 4 )
#We can also create these plots for level total time
ColorTrick1%>%
ggplot(aes(x=timepoint, y=level_total_time, color=ID))+
geom_point()+
geom_line()+
facet_wrap(.~semester)+
ylab("Total Time")
xyplot(level_total_time ~ timepoint | ID, data = ColorTrick1, as.table = T,
xlab = "Timepoint", ylab = "Total Time", grid = T, pch = 19,
type = c("p", "r"), col.line = "darkblue", lwd = 3, lty = 4 )
git config --global nlutz@luc.edu
git config -- global nlutz@luc.edu
git config -- global user.email "nlutz@luc.edu"
git config --global user.email "nlutz@luc.edu"
git config --global user.email "nlutz@luc.edu"
library(tidyverse)
#Reading timepoints 1-6
R1<-read.csv("round1_updated.csv")
R2<-read.csv("round2_updated.csv")
R3<-read.csv("round3_updated.csv")
R4<-read.csv("round4_updated.csv")
R5<-read.csv("round5_updated.csv")
R6<-read.csv("round6_updated.csv")
#Was at 1049 (16 duplicates)
nrow(R5)
#Can filter out using unique timestamp from csv file
R5<- R5%>%
filter(level_start_timestamp != "2021-03-25T18:55:58.767Z")
#Now at 1033
nrow(R5)
#This next step has multiple purposes. First, we are adding "semester" and "timepoint"
#variables to the dataset. Since "user1", "user2"... "usern" was used for both
#semesters, despite these representing different people, I created a new ID variable.
#For semester 1, it is the old ID +100; for semester 2, it is +200.
R1<-mutate(R1, semester=1, timepoint=1, ID = as.factor(as.numeric(gsub("user", "", userid))+100))
R2<-mutate(R2, semester=1, timepoint=2, ID = as.factor(as.numeric(gsub("user", "", userid))+100))
R3<-mutate(R3, semester=1, timepoint=3, ID = as.factor(as.numeric(gsub("user", "", userid))+100))
R4<-mutate(R4, semester=2, timepoint=1, ID = as.factor(as.numeric(gsub("user", "", userid))+200))
R5<-mutate(R5, semester=2, timepoint=2, ID = as.factor(as.numeric(gsub("user", "", userid))+200))
R6<-mutate(R6, semester=2, timepoint=3, ID = as.factor(as.numeric(gsub("user", "", userid))+200))
#Combining all six datasets
Full<-rbind(R1, R2, R3, R4, R5, R6)
#Ensuring the data looks correct and everything merged as expected
str(Full)
#The scorecard variable gives us information about each specific trial. I created
#a new dataset with only the scorecards for each user on each game
Scores<-filter(Full, event_type == "scorecard")
view(Scores)
summary(Scores$level_total_time)
summary(Scores$level_total_time/1000)
sort(Scores$level_total_time)
sort(Scores$level_total_time/1000)
